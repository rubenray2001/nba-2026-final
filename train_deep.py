"""
Deep Learning Training Pipeline
Orchestrates: Data Loading -> Sequence Creation -> LSTM Training -> Evaluation
"""
import pandas as pd
import numpy as np
from models.lstm_model import NBALSTMModel
from data_manager import DataManager
from features_enhanced import EnhancedFeatureEngineer as FeatureEngineer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import config
import os

def create_sequences(X, y, time_steps=10):
    Xs, ys = [], []
    for i in range(len(X) - time_steps):
        Xs.append(X[i:(i + time_steps)])
        ys.append(y[i + time_steps])
    return np.array(Xs), np.array(ys)

def train_deep_model():
    print("="*50)
    print("DEEP LEARNING TRAINING (LSTM)")
    print("="*50)
    
    # 1. Load Data (Reusable from existing pipeline)
    # We use the 'training_data.csv' generated by current pipeline as baseline
    # Ideally we'd use the new AdvancedDataManager, but for MVP orchestration we bridge existing data
    df = pd.read_csv("data/training_data.csv")
    
    # Sort by date for time-series integrity
    df = df.sort_values('date')
    
    # Select Numeric Features
    exclude = ['game_id', 'date', 'home_team_id', 'visitor_team_id', 'home_team_name', 'visitor_team_name', 'season', 'home_won', 'home_score', 'visitor_score']
    features = [c for c in df.columns if c not in exclude]
    
    target = 'home_won'
    
    # Smart NaN filling
    fill_defaults = {}
    for col in features:
        if 'elo' in col.lower(): fill_defaults[col] = 1500
        elif 'win_pct' in col.lower() or 'prob' in col.lower(): fill_defaults[col] = 0.5
        elif 'points_scored' in col.lower() or 'points_allowed' in col.lower(): fill_defaults[col] = 110
        elif 'pace' in col.lower(): fill_defaults[col] = 98
        elif 'rest_days' in col.lower(): fill_defaults[col] = 2
        elif 'vegas_total' in col.lower(): fill_defaults[col] = 220.0
        elif 'vegas_implied' in col.lower(): fill_defaults[col] = 0.5
        else: fill_defaults[col] = 0
    X_raw = df[features].fillna(fill_defaults).values
    y_raw = df[target].values
    
    # 2. Scale
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_raw)
    
    # 3. Create Sequences (Key for LSTM)
    LOOKBACK = 10
    print(f"Creating sequences with lookback={LOOKBACK}...")
    X_seq, y_seq = create_sequences(X_scaled, y_raw, time_steps=LOOKBACK)
    
    print(f"Sequence Shape: {X_seq.shape}")
    
    # 4. Split
    test_size = 0.2
    split_idx = int(len(X_seq) * (1 - test_size))
    
    X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]
    y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]
    
    # 5. Model
    model = NBALSTMModel(input_shape=(LOOKBACK, X_seq.shape[2]))
    
    # 6. Train
    model.train(X_train, y_train, X_test, y_test, epochs=10)
    
    # 7. Evaluate
    loss, acc, auc = model.model.evaluate(X_test, y_test)
    print(f"\nFINAL TEST RESULTS:\nAccuracy: {acc:.2%}\nAUC: {auc:.4f}")
    
    # 8. Save
    os.makedirs("models", exist_ok=True)
    model.save("models/nba_lstm_v1.keras")
    
    return acc

if __name__ == "__main__":
    train_deep_model()
