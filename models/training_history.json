[
  {
    "timestamp": "2026-01-16T20:41:48.770542",
    "training_samples": 2588,
    "test_samples": 647,
    "total_samples": 3235,
    "features": 72,
    "test_accuracy": 0.662,
    "home_score_mae": 9.76,
    "visitor_score_mae": 9.03,
    "overfit_gap": 0.086,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-16T20:41:48.770542",
    "training_samples": 2623,
    "test_samples": 656,
    "total_samples": 3279,
    "features": 72,
    "test_accuracy": 0.664,
    "home_score_mae": 9.7,
    "visitor_score_mae": 8.98,
    "overfit_gap": 0.083,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-16T20:41:48.771862",
    "training_samples": 2658,
    "test_samples": 665,
    "total_samples": 3323,
    "features": 72,
    "test_accuracy": 0.667,
    "home_score_mae": 9.64,
    "visitor_score_mae": 8.92,
    "overfit_gap": 0.081,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-17T22:16:09.299517",
    "training_samples": 2588,
    "test_samples": 647,
    "total_samples": 3235,
    "features": 72,
    "test_accuracy": 0.6676970633693973,
    "home_score_mae": 9.756479189226667,
    "visitor_score_mae": 9.031847169611101,
    "overfit_gap": 0.07998454404945898,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-17T22:25:18.060781",
    "training_samples": 2612,
    "test_samples": 654,
    "total_samples": 3266,
    "features": 72,
    "test_accuracy": 0.6574923547400612,
    "home_score_mae": 9.599753433253563,
    "visitor_score_mae": 8.914776995764058,
    "overfit_gap": 0.08829631294753448,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-18T04:21:27.131011",
    "training_samples": 2612,
    "test_samples": 654,
    "total_samples": 3266,
    "features": 72,
    "test_accuracy": 0.6574923547400612,
    "home_score_mae": 9.598786469690332,
    "visitor_score_mae": 8.91419581092195,
    "overfit_gap": 0.08829631294753448,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-18T21:33:22.295604",
    "training_samples": 2617,
    "test_samples": 655,
    "total_samples": 3272,
    "features": 72,
    "test_accuracy": 0.6687022900763359,
    "home_score_mae": 9.569199754146613,
    "visitor_score_mae": 8.92843483365541,
    "overfit_gap": 0.07527936831113069,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-19T21:26:23.652190",
    "training_samples": 2624,
    "test_samples": 656,
    "total_samples": 3280,
    "features": 72,
    "test_accuracy": 0.6692073170731707,
    "home_score_mae": 9.57084586366903,
    "visitor_score_mae": 8.838989929171397,
    "overfit_gap": 0.07698170731707321,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-20T07:40:55.912367",
    "training_samples": 2624,
    "test_samples": 657,
    "total_samples": 3281,
    "features": 72,
    "test_accuracy": 0.624048706240487,
    "home_score_mae": 10.013181717986246,
    "visitor_score_mae": 8.999435475508763,
    "overfit_gap": 0.09622568400341536,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-20T10:50:55.057828",
    "training_samples": 23897,
    "test_samples": 5975,
    "total_samples": 29872,
    "features": 72,
    "test_accuracy": 0.6354811715481171,
    "home_score_mae": 9.782094517151055,
    "visitor_score_mae": 9.211458715153762,
    "overfit_gap": 0.03071123754088989,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-20T11:23:39.821346",
    "training_samples": 23897,
    "test_samples": 5975,
    "total_samples": 29872,
    "features": 72,
    "test_accuracy": 0.6354811715481171,
    "home_score_mae": 9.782094517151053,
    "visitor_score_mae": 9.211458715153762,
    "overfit_gap": 0.03071123754088989,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-20T11:33:49.551946",
    "training_samples": 23901,
    "test_samples": 5976,
    "total_samples": 29877,
    "features": 76,
    "test_accuracy": 0.5555555555555556,
    "home_score_mae": 10.227237519816805,
    "visitor_score_mae": 9.380722536078883,
    "overfit_gap": 0.05362397668158936,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-20T11:42:21.997929",
    "training_samples": 23901,
    "test_samples": 5976,
    "total_samples": 29877,
    "features": 76,
    "test_accuracy": 0.5505354752342704,
    "home_score_mae": 10.226370446625394,
    "visitor_score_mae": 9.387704139252186,
    "overfit_gap": 0.07705332858146952,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-20T13:31:52.931254",
    "training_samples": 1052,
    "test_samples": 264,
    "total_samples": 1316,
    "features": 76,
    "test_accuracy": 0.6856060606060606,
    "home_score_mae": 8.551805361397719,
    "visitor_score_mae": 8.97845405102737,
    "overfit_gap": 0.08150420555363524,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-21T00:04:34.599945",
    "training_samples": 26160,
    "test_samples": 6541,
    "total_samples": 32701,
    "features": 93,
    "test_accuracy": 0.5535850787341385,
    "home_score_mae": 10.238792771037105,
    "visitor_score_mae": 9.38236908367335,
    "overfit_gap": 0.056506664385127525,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-21T00:11:01.535063",
    "training_samples": 26160,
    "test_samples": 6541,
    "total_samples": 32701,
    "features": 93,
    "test_accuracy": 0.5535850787341385,
    "home_score_mae": 10.238792771037105,
    "visitor_score_mae": 9.38236908367335,
    "overfit_gap": 0.056506664385127525,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-21T00:26:16.453111",
    "training_samples": 26160,
    "test_samples": 6541,
    "total_samples": 32701,
    "features": 93,
    "test_accuracy": 0.5535850787341385,
    "home_score_mae": 10.238792771037105,
    "visitor_score_mae": 9.38236908367335,
    "overfit_gap": 0.056506664385127525,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-21T00:28:15.753856",
    "training_samples": 26160,
    "test_samples": 6541,
    "total_samples": 32701,
    "features": 93,
    "test_accuracy": 0.5535850787341385,
    "home_score_mae": 10.238792771037105,
    "visitor_score_mae": 9.38236908367335,
    "overfit_gap": 0.056506664385127525,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-21T07:27:32.154779",
    "training_samples": 26160,
    "test_samples": 6541,
    "total_samples": 32701,
    "features": 93,
    "test_accuracy": 0.5535850787341385,
    "home_score_mae": 10.238792771037105,
    "visitor_score_mae": 9.38236908367335,
    "overfit_gap": 0.056506664385127525,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-22T12:02:50.116018",
    "training_samples": 26160,
    "test_samples": 6541,
    "total_samples": 32701,
    "features": 93,
    "test_accuracy": 0.5535850787341385,
    "home_score_mae": 10.238792771037105,
    "visitor_score_mae": 9.38236908367335,
    "overfit_gap": 0.056506664385127525,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-22T12:04:18.027589",
    "training_samples": 26160,
    "test_samples": 6541,
    "total_samples": 32701,
    "features": 93,
    "test_accuracy": 0.5535850787341385,
    "home_score_mae": 10.238792771037105,
    "visitor_score_mae": 9.38236908367335,
    "overfit_gap": 0.056506664385127525,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-23T04:20:16.323603",
    "training_samples": 26160,
    "test_samples": 6541,
    "total_samples": 32701,
    "features": 93,
    "test_accuracy": 0.5535850787341385,
    "home_score_mae": 10.238792771037105,
    "visitor_score_mae": 9.38236908367335,
    "overfit_gap": 0.056506664385127525,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-23T04:31:55.902044",
    "training_samples": 26160,
    "test_samples": 6541,
    "total_samples": 32701,
    "features": 93,
    "test_accuracy": 0.5535850787341385,
    "home_score_mae": 10.238792771037105,
    "visitor_score_mae": 9.38236908367335,
    "overfit_gap": 0.056506664385127525,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-23T21:33:08.465758",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6535947712418301,
    "home_score_mae": 9.584345773586506,
    "visitor_score_mae": 9.429694607996439,
    "overfit_gap": 0.1613007782586241,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-23T21:56:55.239695",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6535947712418301,
    "home_score_mae": 9.584345773586508,
    "visitor_score_mae": 9.42969460799644,
    "overfit_gap": 0.1613007782586241,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-23T22:40:01.275799",
    "training_samples": 2555,
    "test_samples": 639,
    "total_samples": 3194,
    "features": 30,
    "test_accuracy": 0.6353677621283255,
    "train_accuracy": 0.6590998043052838,
    "home_score_mae": 9.859693427635612,
    "visitor_score_mae": 9.24109826680604,
    "overfit_gap": 0.023732042176958346,
    "model_type": "optimized_regularized"
  },
  {
    "timestamp": "2026-01-23T22:40:27.029412",
    "training_samples": 2555,
    "test_samples": 639,
    "total_samples": 3194,
    "features": 30,
    "test_accuracy": 0.6353677621283255,
    "train_accuracy": 0.6590998043052838,
    "home_score_mae": 9.859693427635612,
    "visitor_score_mae": 9.24109826680604,
    "overfit_gap": 0.023732042176958346,
    "model_type": "optimized_regularized"
  },
  {
    "timestamp": "2026-01-23T22:49:59.738855",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6535947712418301,
    "home_score_mae": 9.584345773586508,
    "visitor_score_mae": 9.429694607996439,
    "overfit_gap": 0.1613007782586241,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-26T08:08:07.618499",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.663761801016703,
    "home_score_mae": 9.671879527088315,
    "visitor_score_mae": 9.447792200156005,
    "overfit_gap": 0.14913556501417802,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-26T08:22:30.132356",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.663761801016703,
    "home_score_mae": 9.671879527088315,
    "visitor_score_mae": 9.447792200156007,
    "overfit_gap": 0.14913556501417802,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-26T08:34:45.888968",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.663761801016703,
    "home_score_mae": 9.671879527088313,
    "visitor_score_mae": 9.447792200156005,
    "overfit_gap": 0.14913556501417802,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-26T08:41:33.341898",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.663761801016703,
    "home_score_mae": 9.671879527088315,
    "visitor_score_mae": 9.447792200156007,
    "overfit_gap": 0.14913556501417802,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-26T08:49:39.577472",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.663761801016703,
    "home_score_mae": 9.671879527088315,
    "visitor_score_mae": 9.447792200156007,
    "overfit_gap": 0.14913556501417802,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-26T09:08:23.865845",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6434277414669571,
    "home_score_mae": 9.707071424194615,
    "visitor_score_mae": 9.543661853878607,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-27T14:08:19.147228",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6434277414669571,
    "home_score_mae": 9.707071424194615,
    "visitor_score_mae": 9.543661853878605,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-28T21:35:15.227938",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6434277414669571,
    "home_score_mae": 9.707071424194615,
    "visitor_score_mae": 9.543661853878607,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-30T08:13:42.852582",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6434277414669571,
    "home_score_mae": 9.707071424194615,
    "visitor_score_mae": 9.543661853878607,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-01-30T21:21:54.603479",
    "training_samples": 3618,
    "test_samples": 905,
    "total_samples": 4523,
    "features": 40,
    "test_accuracy": 0.6419889502762431,
    "train_accuracy": 0.7048092868988391,
    "home_score_mae": 9.768733003437296,
    "visitor_score_mae": 9.493656412022235,
    "overfit_gap": 0.062820336622596,
    "brier_score": 0.22056051255078227,
    "model_type": "enhanced_calibrated"
  },
  {
    "timestamp": "2026-01-30T21:29:31.304463",
    "training_samples": 3618,
    "test_samples": 905,
    "features": 50,
    "test_accuracy": 0.6464088397790055,
    "train_accuracy": 0.7788833609729132,
    "home_score_mae": 9.78857023017184,
    "visitor_score_mae": 9.520489110550237,
    "overfit_gap": 0.13247452119390768,
    "brier_score": 0.2215350752569693,
    "model_type": "full_enhanced",
    "enhancements": [
      "vegas",
      "h2h",
      "situational"
    ]
  },
  {
    "timestamp": "2026-01-31T04:18:41.316123",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6434277414669571,
    "home_score_mae": 9.707071424194615,
    "visitor_score_mae": 9.543661853878605,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-02-01T04:17:09.777901",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6434277414669571,
    "home_score_mae": 9.707071424194615,
    "visitor_score_mae": 9.543661853878607,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-02-01T23:10:53.706893",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6434277414669571,
    "home_score_mae": 9.707071424194616,
    "visitor_score_mae": 9.543661853878607,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-02-02T21:49:03.882151",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6434277414669571,
    "home_score_mae": 9.707071424194615,
    "visitor_score_mae": 9.543661853878605,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-02-04T10:56:27.456822",
    "training_samples": 5505,
    "test_samples": 1377,
    "total_samples": 6882,
    "features": 93,
    "test_accuracy": 0.6434277414669571,
    "home_score_mae": 9.707071424194615,
    "visitor_score_mae": 9.543661853878605,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-02-05T10:57:11.718336",
    "training_samples": 25804,
    "test_samples": 6452,
    "total_samples": 32256,
    "features": 93,
    "test_accuracy": 0.639026658400496,
    "home_score_mae": 9.410617023507099,
    "visitor_score_mae": 9.396811952249328,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-02-05T22:51:32.472289",
    "training_samples": 25817,
    "test_samples": 6455,
    "total_samples": 32272,
    "features": 130,
    "test_accuracy": 0.6395042602633617,
    "home_score_mae": 9.555084400119297,
    "visitor_score_mae": 9.647723203281393,
    "overfit_gap": 0,
    "model_type": "unknown"
  },
  {
    "timestamp": "2026-02-05T23:01:43.601192",
    "training_samples": 25817,
    "test_samples": 6455,
    "total_samples": 32272,
    "features": 130,
    "test_accuracy": 0.6395042602633617,
    "home_score_mae": 9.555084400119298,
    "visitor_score_mae": 9.64772320328139,
    "overfit_gap": 0,
    "model_type": "unknown"
  }
]